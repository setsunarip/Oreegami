{"cells":[{"cell_type":"markdown","id":"db4b11b8","metadata":{"id":"db4b11b8"},"source":["# Exercice : Construisez et Améliorez un Chatbot Simple"]},{"cell_type":"markdown","id":"bb2a4131","metadata":{"id":"bb2a4131"},"source":["L'objectif de cet exercice est de comprendre comment utiliser un modèle de langage pré-entraîné avec Hugging Face et de personnaliser ses réponses."]},{"cell_type":"markdown","id":"743d51f9","metadata":{"id":"743d51f9"},"source":["## Étape 1 : Comprendre le code de base"]},{"cell_type":"markdown","id":"cc5f6897","metadata":{"id":"cc5f6897"},"source":["Voici le code de base pour créer un chatbot simple en utilisant le modèle `DialoGPT` de Hugging Face."]},{"cell_type":"code","execution_count":null,"id":"72d1b293","metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/","height":316},"id":"72d1b293"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"404690078bca4971b4caf0d84b5053e1","version_major":2,"version_minor":0},"text/plain":["tokenizer_config.json:   0%|          | 0.00/614 [00:00\u003c?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"cc09d3f9ac4f4103a67148a633c0c0e6","version_major":2,"version_minor":0},"text/plain":["vocab.json:   0%|          | 0.00/1.04M [00:00\u003c?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"4623cec02fd644069b3ffd394dc888ab","version_major":2,"version_minor":0},"text/plain":["merges.txt:   0%|          | 0.00/456k [00:00\u003c?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"633cd89080344bc9960383a371b84429","version_major":2,"version_minor":0},"text/plain":["config.json:   0%|          | 0.00/641 [00:00\u003c?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"bcdc0c9e1ba14ec197166823871c46fe","version_major":2,"version_minor":0},"text/plain":["model.safetensors:   0%|          | 0.00/351M [00:00\u003c?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"56aaf8bf71ff4671bf7d3109ce66e1b0","version_major":2,"version_minor":0},"text/plain":["generation_config.json:   0%|          | 0.00/124 [00:00\u003c?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Chatbot prêt. Tapez 'exit' pour quitter.\n"]},{"name":"stderr","output_type":"stream","text":["The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"]},{"name":"stdout","output_type":"stream","text":["Chatbot: Hi\n"]}],"source":["\n","from transformers import AutoModelForCausalLM, AutoTokenizer\n","import torch\n","\n","# Charger le modèle et le tokenizer\n","model_name = \"microsoft/DialoGPT-small\"  # Modèle léger\n","tokenizer = AutoTokenizer.from_pretrained(model_name)\n","model = AutoModelForCausalLM.from_pretrained(model_name)\n","\n","# Fonction de conversation\n","def chat_with_bot(input_text, chat_history_ids=None):\n","    new_input_ids = tokenizer.encode(input_text + tokenizer.eos_token, return_tensors=\"pt\")\n","    bot_input_ids = torch.cat([chat_history_ids, new_input_ids], dim=-1) if chat_history_ids is not None else new_input_ids\n","    chat_history_ids = model.generate(bot_input_ids, max_length=1000, pad_token_id=tokenizer.eos_token_id)\n","    response = tokenizer.decode(chat_history_ids[:, bot_input_ids.shape[-1]:][0], skip_special_tokens=True)\n","    return response, chat_history_ids\n","\n","# Boucle interactive\n","print(\"Chatbot prêt. Tapez 'exit' pour quitter.\")\n","chat_history = None\n","\n","while True:\n","    user_input = input(\"Vous: \")\n","    if user_input.lower() == \"exit\":\n","        print(\"Chatbot: Au revoir!\")\n","        break\n","    response, chat_history = chat_with_bot(user_input, chat_history)\n","    print(f\"Chatbot: {response}\")\n"]},{"cell_type":"markdown","id":"6e92bb0c","metadata":{"id":"6e92bb0c"},"source":["## Étape 2 : Questions (répondez dans des cellules texte sur le notebook)"]},{"cell_type":"markdown","id":"037b2312","metadata":{"id":"037b2312"},"source":["\n","1. **Identification du code :**\n","   - Que fait la fonction `chat_with_bot()` ? Décrivez son rôle dans le chatbot\n","   - Pourquoi utilisons-nous `torch.cat` dans ce script ?\n","\n","2. **Test initial :**\n","   - Exécutez le code et testez le chatbot. Essayez plusieurs entrées pour observer ses réponses  \n","   - Notez ses points faibles\n","    "]},{"cell_type":"markdown","id":"a94588a1","metadata":{"id":"a94588a1"},"source":["## Étape 3 : Améliorations à implémenter"]},{"cell_type":"markdown","id":"1826619a","metadata":{"id":"1826619a"},"source":["\n","Proposez des tâches d'amélioration pour rendre le chatbot plus utile :\n","\n","1. **Limiter la longueur de l'historique :**\n","   - Modifiez le code pour ne conserver que les 3 derniers échanges dans l'historique. (Indice : Utilisez une liste pour gérer les messages.)\n","   \n","2. **Personnalisation des réponses :**\n","   - Ajoutez une condition pour que le chatbot réponde de manière différente à des phrases spécifiques. Exemple :\n","     ```python\n","     if \"ton nom\" in user_input.lower():\n","         print(\"Chatbot: Mon nom est ChatbotGPT!\")\n","         continue\n","     ```\n","\n","3. **Changer le modèle :**\n","   - Remplacez `microsoft/DialoGPT-small` par `microsoft/DialoGPT-medium` ou un autre modèle\n","   - Observez les différences dans les réponses\n","\n","4. **Ajout de métriques :**\n","   - Comptez le nombre de messages échangés entre l'utilisateur et le chatbot\n","   - Affichez ce nombre lorsque l'utilisateur tape \"statistiques\"\n","    "]},{"cell_type":"markdown","id":"bd175a2b","metadata":{"id":"bd175a2b"},"source":["## Étape 4 : Défi avancé"]},{"cell_type":"markdown","id":"be5c48da","metadata":{"id":"be5c48da"},"source":["\n","1. **Sauvegarder la conversation :**\n","   - Modifiez le script pour enregistrer toutes les conversations dans un fichier texte.\n","   - Exemple :\n","     ```python\n","     with open(\"conversation_log.txt\", \"a\") as log_file:\n","         log_file.write(f\"Vous: {user_input}\\nChatbot: {response}\\n\")\n","     ```\n","\n","2. **Créer une interface utilisateur simple :**\n","   - Utilisez `tkinter` ou une bibliothèque comme `streamlit` pour créer une interface graphique où l'utilisateur peut interagir avec le chatbot.\n","    "]},{"cell_type":"markdown","id":"057a0197","metadata":{"id":"057a0197"},"source":["## Étape 5 : Prise de hauteur"]},{"cell_type":"markdown","id":"7b4c6d8b","metadata":{"id":"7b4c6d8b"},"source":["\n","\n","*   Élément de liste\n","*   Élément de liste\n","\n","\n","1. Quels sont les avantages d'utiliser un modèle pré-entraîné ?\n","2. Quels seraient les défis pour personnaliser ce modèle pour un cas spécifique (par exemple, chatbot pour support technique) ?\n","    "]}],"metadata":{"colab":{"name":"","version":""},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":5}